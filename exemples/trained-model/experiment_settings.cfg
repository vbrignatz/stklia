[Hyperparams]
lr = 0.2
batch_size = 256
max_seq_len = 400
no_cuda = False
seed = 1234
num_iterations = 5000
momentum = 0.9
scheduler_steps = [2500, 3000, 4000]
scheduler_lambda = 0.5
multi_gpu = False

[Dataset]
features_per_frame = 61

[Model]
emb_size = 256
layers = [3, 4, 6, 3]
num_filters = [32, 64, 128, 256]
zero_init_residual = True
# [min, max, mean, std, statistical]
pooling = std

[Outputs]
model_dir = exemples/trained-model/
checkpoint_interval = 10
checkpoints_dir = checkpoints
log_interval = 1
